# Random Forest Model for Bitterness Classification in Cheddar

Implementation of random forest algorithm in R for classification of peptides as bitter or non-bitter based on MS abundance results

------------------------------------------------------------------------

This model was build for Biological Data Science Course MB599 at Oregon State University, to classify peptides as bitter or non-bitter in relation to the physical properties of the peptides and their mass spec abundance in cheese samples determined to be bitter or non-bitter.

------------------------------------------------------------------------

**THE MODEL WAS NOT INCOPERATED IN FINAL PROJECT DUE TO ERRONOUS INPUT DATA**

------------------------------------------------------------------------

The script used the template and followed the procedure documented Dr. Christine Tataru on the prediction of bee type based on microbiome data.

------------------------------------------------------------------------

***Random forest***

Following ordination, the data was centered for the model to make quantitative prediction of variable importance of the variables. This was performed by the caret package and using the formula:

(x-mean(x))/sd(x).

To determine the potential importance of a peptide to the bitterness of a cheese, a machine learning random forest algorithm was employed. This algorithm is widely used in bioinformatics due to its effectiveness at the classification task (Zhao et al. 2021). The task in this study is classification of a peptide as bitter or non-bitter based on MS relative abundance in the 7 bitter and 7 non-bitter cheese samples. The random forest model uses a selection method based on MS abundance data matrix of samples and variables (peptides) to construct decision trees. The algorithm then votes on these decision trees identifying the results and mean variable importance of each peptide which is the degree to which each peptide contributes to the observed difference between the bitter and non-bitter groups.

A list of the random forest models predicted most important peptides (variables) and the mean variable importance was generated by averaging the prediction of 250 model re-iterations. However, the direction of the importance was not highlighted as only the magnitude of importance\'s of each variable\'s peptide was predicted not if it\'s associated with higher abundances in the bitter samples.

------------------------------------------------------------------------

***Principal Coordinates of Analysis***

To have a visualization of dissimilarity in the peptidomic
profile of the sample 14 samples in relationship to their bitterness grouping a principal coordinates analysis (PCoA) analysis is
illustrated in Figure. 4. The PCoA plot reveals no clear grouping between bitter and non-bitter samples based on the peptidomic profiles of each sample. All the non-bitter peptides have an Axis.1 (50.4% of variation) value of less than 0.1, however so do 3 of the 7 bitter samples including the extremely bitter sample E_5.7 (bitterness value of 3.0). Axis.2 which captures 18% of the variation has no clear definition between the bitter and non-bitter grouping. The PCoA plot indicates the peptidomic profile can\'t explain the differences of bitterness between the samples and a comprehensive investigation of the individuals\' peptides relationship to bitterness is required.

------------------------------------------------------------------------

***Construction of and Model Optimization***

To construct the predictive model, the caret package in Rstudio (V.4.22) was used to partition the data set with 70% samples for training and 30% samples for testing. An optimal tree depth of 18 was selected as it demonstrated the best fit for the model. 3-fold cross-validation of the model occurred with 3 repeats.

The decision tree parameters were optimized with the number of
trees (ntree) equal to 500, tree depth (mtry) = 13 (accuracy = 0.85, kappa =0.70) and cross validation values of 4- fold and 3 repeats, which resulted in an out-of-bag (OOB) error of 20%. The confusion matrix indicated 40% classification error for bitter and a 0% classification of non-bitter on the 10-sample training set.
